{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm\n",
    "\n",
    "## Problem\n",
    "\n",
    "You are given a dataset related to damage after a Nepalese earthquake. A detailed description of the dataset is provided below. The data is processed by the following code cells. In other words, these cells will take care of some data preprocessing for you, so please run them.\n",
    "\n",
    "Your task is to train a neural network to predict the numeric class of damage (classification problem) from 1-3. \n",
    "\n",
    "The task is open ended, but your goal, in the spirit of online machine learning contests, is to maximize a given metric. Here that metric is the F1 score with micro averaging. See this URL for details and a convienent implementation (which you should use) https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html. \n",
    "\n",
    "In practice you would split this dataset into three sections: training, validation, and test. Instead, please split the data with 80% train and 20% validation. During training, monitor the validation loss and compute the F1 metric on that validation data. This score will be the final score you report. \n",
    "\n",
    "The baseline F1 score for this dataset is 0.58, upon which you should be able to improve with the neural net. \n",
    "\n",
    "\n",
    "### Data Description\n",
    "\n",
    "Following the 7.8 Mw Gorkha Earthquake on April 25, 2015, Nepal carried out a massive household survey using mobile technology to assess building damage in the earthquake-affected districts. Although the primary goal of this survey was to identify beneficiaries eligible for government assistance for housing reconstruction, it also collected other useful socio-economic information. In addition to housing reconstruction, this data serves a wide range of uses and users e.g. researchers, newly formed local governments, and citizens at large. \n",
    "\n",
    "### Labels\n",
    "\n",
    "Three numeric labels represent damage grade:\n",
    "\n",
    "1) Low Damage\n",
    "\n",
    "2) Moderate Damage\n",
    "\n",
    "3) Complete Destruction\n",
    "\n",
    "\n",
    "### Features\n",
    "geo_level_1_id: High level geographic location\n",
    "\n",
    "geo_level_2_id: Mid level geographic location\n",
    "\n",
    "geo_level_3_id: Low level geographic location\n",
    "\n",
    "count_floors_pre_eq (type: int): number of floors in the building before the earthquake.\n",
    "\n",
    "age (type: int): age of the building in years.\n",
    "\n",
    "area_percentage (type: int): normalized area of the building footprint.\n",
    "\n",
    "height_percentage (type: int): normalized height of the building footprint.\n",
    "\n",
    "land_surface_condition (type: categorical): surface condition of the land where the building was built. Possible values: n, o, t.\n",
    "\n",
    "foundation_type (type: categorical): type of foundation used while building. Possible values: h, i, r, u, w.\n",
    "\n",
    "roof_type (type: categorical): type of roof used while building. Possible values: n, q, x.\n",
    "\n",
    "ground_floor_type (type: categorical): type of the ground floor. Possible values: f, m, v, x, z.\n",
    "\n",
    "other_floor_type (type: categorical): type of constructions used in higher than the ground floors (except of roof). Possible values: j, q, s, x.\n",
    "\n",
    "position (type: categorical): position of the building. Possible values: j, o, s, t.\n",
    "\n",
    "plan_configuration (type: categorical): building plan configuration. Possible values: a, c, d, f, m, n, o, q, s, u.\n",
    "\n",
    "has_superstructure_adobe_mud (type: binary): flag variable that indicates if the superstructure was made of Adobe/Mud.\n",
    "\n",
    "has_superstructure_mud_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Stone.\n",
    "\n",
    "has_superstructure_stone_flag (type: binary): flag variable that indicates if the superstructure was made of Stone.\n",
    "has_superstructure_cement_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Stone.\n",
    "has_superstructure_mud_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Brick.\n",
    "has_superstructure_cement_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Brick.\n",
    "\n",
    "has_superstructure_timber (type: binary): flag variable that indicates if the superstructure was made of Timber.\n",
    "\n",
    "has_superstructure_bamboo (type: binary): flag variable that indicates if the superstructure was made of Bamboo.\n",
    "\n",
    "has_superstructure_rc_non_engineered (type: binary): flag variable that indicates if the superstructure was made of non-engineered reinforced concrete.\n",
    "\n",
    "has_superstructure_rc_engineered (type: binary): flag variable that indicates if the superstructure was made of engineered reinforced concrete.\n",
    "\n",
    "has_superstructure_other (type: binary): flag variable that indicates if the superstructure was made of any other material.\n",
    "\n",
    "\n",
    "count_families (type: int): number of families that live in the building.\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "You should submit the complete code (with cell outputs) showing your train/validation split, any other preprocessing on the training data or labels, your neural network, training loss and validation loss plots, f1 score on the validation data, and the confusion matrix.\n",
    "\n",
    "In addition to the complete code, in a text cell or in a seperate document, write up your methodology, results, and some discussion of the results. Also discuss the specific choices (e.g. loss function, optimizer) you made in that process.\n",
    "\n",
    "### Note\n",
    "\n",
    "This is a real world dataset, so you will likely not be able to acheive > 0.75 F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "#Some metrics and utilities\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import seaborn as sn\n",
    "import re\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train_values.csv')\n",
    "training_labels = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>count_families</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.463345</td>\n",
       "      <td>0.491293</td>\n",
       "      <td>0.497961</td>\n",
       "      <td>0.141215</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.070889</td>\n",
       "      <td>0.114479</td>\n",
       "      <td>0.152286</td>\n",
       "      <td>0.081396</td>\n",
       "      <td>0.180241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034332</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.254988</td>\n",
       "      <td>0.085011</td>\n",
       "      <td>0.042590</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.267787</td>\n",
       "      <td>0.289216</td>\n",
       "      <td>0.290154</td>\n",
       "      <td>0.090958</td>\n",
       "      <td>0.198003</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.063947</td>\n",
       "      <td>0.348020</td>\n",
       "      <td>0.208532</td>\n",
       "      <td>0.297798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182081</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.252010</td>\n",
       "      <td>0.263824</td>\n",
       "      <td>0.435855</td>\n",
       "      <td>0.278899</td>\n",
       "      <td>0.201931</td>\n",
       "      <td>0.124932</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>0.069516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.245270</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.491941</td>\n",
       "      <td>0.498926</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.735809</td>\n",
       "      <td>0.748946</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "count   260601.000000   260601.000000   260601.000000        260601.000000   \n",
       "mean         0.463345        0.491293        0.497961             0.141215   \n",
       "std          0.267787        0.289216        0.290154             0.090958   \n",
       "min          0.000000        0.000000        0.000000             0.000000   \n",
       "25%          0.233333        0.245270        0.244529             0.125000   \n",
       "50%          0.400000        0.491941        0.498926             0.125000   \n",
       "75%          0.700000        0.735809        0.748946             0.125000   \n",
       "max          1.000000        1.000000        1.000000             1.000000   \n",
       "\n",
       "                 age  area_percentage  height_percentage  \\\n",
       "count  260601.000000    260601.000000      260601.000000   \n",
       "mean        0.216562         0.070889           0.114479   \n",
       "std         0.198003         0.044366           0.063947   \n",
       "min         0.000000         0.000000           0.000000   \n",
       "25%         0.100000         0.040404           0.066667   \n",
       "50%         0.150000         0.060606           0.100000   \n",
       "75%         0.300000         0.080808           0.133333   \n",
       "max         1.000000         1.000000           1.000000   \n",
       "\n",
       "       land_surface_condition  foundation_type      roof_type  ...  \\\n",
       "count           260601.000000    260601.000000  260601.000000  ...   \n",
       "mean                 0.152286         0.081396       0.180241  ...   \n",
       "std                  0.348020         0.208532       0.297798  ...   \n",
       "min                  0.000000         0.000000       0.000000  ...   \n",
       "25%                  0.000000         0.000000       0.000000  ...   \n",
       "50%                  0.000000         0.000000       0.000000  ...   \n",
       "75%                  0.000000         0.000000       0.500000  ...   \n",
       "max                  1.000000         1.000000       1.000000  ...   \n",
       "\n",
       "       has_superstructure_stone_flag  has_superstructure_cement_mortar_stone  \\\n",
       "count                  260601.000000                           260601.000000   \n",
       "mean                        0.034332                                0.018235   \n",
       "std                         0.182081                                0.133800   \n",
       "min                         0.000000                                0.000000   \n",
       "25%                         0.000000                                0.000000   \n",
       "50%                         0.000000                                0.000000   \n",
       "75%                         0.000000                                0.000000   \n",
       "max                         1.000000                                1.000000   \n",
       "\n",
       "       has_superstructure_mud_mortar_brick  \\\n",
       "count                        260601.000000   \n",
       "mean                              0.068154   \n",
       "std                               0.252010   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.000000   \n",
       "max                               1.000000   \n",
       "\n",
       "       has_superstructure_cement_mortar_brick  has_superstructure_timber  \\\n",
       "count                           260601.000000              260601.000000   \n",
       "mean                                 0.075268                   0.254988   \n",
       "std                                  0.263824                   0.435855   \n",
       "min                                  0.000000                   0.000000   \n",
       "25%                                  0.000000                   0.000000   \n",
       "50%                                  0.000000                   0.000000   \n",
       "75%                                  0.000000                   1.000000   \n",
       "max                                  1.000000                   1.000000   \n",
       "\n",
       "       has_superstructure_bamboo  has_superstructure_rc_non_engineered  \\\n",
       "count              260601.000000                         260601.000000   \n",
       "mean                    0.085011                              0.042590   \n",
       "std                     0.278899                              0.201931   \n",
       "min                     0.000000                              0.000000   \n",
       "25%                     0.000000                              0.000000   \n",
       "50%                     0.000000                              0.000000   \n",
       "75%                     0.000000                              0.000000   \n",
       "max                     1.000000                              1.000000   \n",
       "\n",
       "       has_superstructure_rc_engineered  has_superstructure_other  \\\n",
       "count                     260601.000000             260601.000000   \n",
       "mean                           0.015859                  0.014985   \n",
       "std                            0.124932                  0.121491   \n",
       "min                            0.000000                  0.000000   \n",
       "25%                            0.000000                  0.000000   \n",
       "50%                            0.000000                  0.000000   \n",
       "75%                            0.000000                  0.000000   \n",
       "max                            1.000000                  1.000000   \n",
       "\n",
       "       count_families  \n",
       "count   260601.000000  \n",
       "mean         0.163977  \n",
       "std          0.069516  \n",
       "min          0.000000  \n",
       "25%          0.166667  \n",
       "50%          0.166667  \n",
       "75%          0.166667  \n",
       "max          1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list to aggregate the columns that have a secondary use\n",
    "remove_cols = []\n",
    "\n",
    "#Identify all the columns with a secondary use\n",
    "for item in training_data.columns:\n",
    "    if re.findall(\"has_secondary_use\",item):\n",
    "        remove_cols.append(item)\n",
    "        \n",
    "#Remove secondary use fields and other fields that are not useful\n",
    "training_data = training_data.drop(remove_cols, axis = 1)\n",
    "training_data = training_data.drop(['legal_ownership_status', 'building_id'], axis = 1)\n",
    "training_labels = training_labels.drop('building_id', axis = 1)\n",
    "\n",
    "#Change string classes to numeric values\n",
    "training_data['land_surface_condition'] = training_data['land_surface_condition'].map({'t':1, 'o':2, 'n':3})\n",
    "training_data['foundation_type'] = training_data['foundation_type'].map({'r': 1, 'w': 2, 'i':3, 'u':4, 'h':5})\n",
    "training_data['roof_type'] = training_data['roof_type'].map({'n':1, 'q':2, 'x':3})\n",
    "training_data['ground_floor_type'] = training_data['ground_floor_type'].map({'f':1, 'x':2, 'v':3, 'z':4, 'm':5})\n",
    "training_data['other_floor_type'] = training_data['other_floor_type'].map({'q':1, 'x':2, 'j':3, 's':4})\n",
    "training_data['position'] = training_data['position'].map({'t':1, 's':2, 'j':3, 'o':4})\n",
    "training_data['plan_configuration'] = training_data['plan_configuration'].map({'d':1, 'u':2, 's':3, 'q':4, 'm':5, 'c':6, 'a':7, 'n':8, 'f':9, 'o':10})\n",
    "\n",
    "def normalize_zero_one(array):\n",
    "    minimum = np.min(array)\n",
    "    maximum = np.max(array)\n",
    "    return (array-minimum)/(maximum-minimum)\n",
    "\n",
    "#Clip age and family counts because they have strong outliers\n",
    "training_data['age'] = np.clip(training_data['age'], 0, 100)\n",
    "training_data['count_families'] = np.clip(training_data['count_families'], 0, 6)\n",
    "\n",
    "#Normalize 0-1\n",
    "norm_cats = ['age','count_families', 'geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'area_percentage', \n",
    "              'count_floors_pre_eq', 'height_percentage', 'land_surface_condition', 'roof_type', 'foundation_type']\n",
    "\n",
    "#normalize categories to interval 0-1\n",
    "for column in norm_cats:\n",
    "    training_data[column] = normalize_zero_one(training_data[column])\n",
    "    \n",
    "#check that everything has been done correctly\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks (pass these to model.fit as callbacks = callbacks to help with the training) See keras callbacks documentation for more details\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='Best_model.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=True, mode='auto')\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=100, verbose = 1)\n",
    "\n",
    "callbacks = [early_stopping,\n",
    "            model_checkpoint]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
